### Dataset collected
- `data/gpt-4_results.csv` contains all the experiments data for `GPT-4`
- `data/gpt-3.5-turbo_results.csv` contains all the experiments data for `ChatGPT`
- `data/text-davinci-003_results.csv` contains all the experiments data for `text-davinci-003`
- `data/acm_ccs_200.titles` contains the 200 sampled topics from ACM
- main fields - `gen_title`: title generated by the LM, `title`: concept from ACM, `bing_return`: whether Bing returned any results when queried with the `gen_title`?, `model_ans_1|2|3`: author names from the LM sampled 3 times, `neural_ans1|2|3|4_list`: list of answers (10) from the LM for IQ, DQ1,DQ2,DQ3 methods, `neural_ans1|2|3|4_prob` : score calculated using the lists.


### Dataset for the expert manual annotations

- `data/expert_annotation_study/` contains the data for the expert manual annotations on 100 randomly sampled titles.
- `data/expert_annotation_study/expert_A.csv` contains the labelling by expert A
- `data/expert_annotation_study/expert_B.csv` contains the labelling by expert B
- `data/expert_annotation_study/expert_C.csv` contains the labelling by expert C
- `data/expert_annotation_study/expert_D.csv` contains the labelling by expert D
- `data/expert_annotation_study/ground_truth.csv` contains the ground truth labels by Bing

