{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from roc_utils import *\n",
    "from auc_delong_xu import auc_ci_Delong\n",
    "import roc_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  pd.read_csv(\"<YOUR PATH>/code_and_data/gpt-4_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"bing_return\"].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_label = 1\n",
    "n_samples = 100\n",
    "# aIQuming your dataframe is called df and has columns \"probs\" and \"ground truth\"\n",
    "list_baselines =  [\"IQ\",\"DQ1\",\"DQ2\",\"DQ3\"]#,\"IQ+DQ2\"]\n",
    "dict_baselines = {\"IQ\":{\"ground_truth\" : None, \"probs\" : None},\"DQ1\":{\"ground_truth\" : None, \"probs\" : None},\"DQ2\":{\"ground_truth\" : None, \"probs\" : None},\"DQ3\":{\"ground_truth\" : None, \"probs\" : None}}#, \"IQ+DQ2\" : {\"ground_truth\" : None, \"probs\" : None}}\n",
    "\n",
    "probs = df[\"neural_ans1_prob\"].values\n",
    "dict_baselines[\"IQ\"][\"probs\"] = 1 - probs\n",
    "ground_truth = df[\"bing_return\"].values\n",
    "ground_truth = [0 if x == True else 1 for x in ground_truth]\n",
    "ground_truth = np.array(ground_truth)\n",
    "dict_baselines[\"IQ\"][\"ground_truth\"] = ground_truth\n",
    "\n",
    "probs = df[\"neural_ans2_prob\"].values\n",
    "dict_baselines[\"DQ1\"][\"probs\"] = 1 - probs\n",
    "ground_truth = df[\"bing_return\"].values\n",
    "ground_truth = [0 if x == True else 1 for x in ground_truth]\n",
    "ground_truth = np.array(ground_truth)\n",
    "dict_baselines[\"DQ1\"][\"ground_truth\"] = ground_truth\n",
    "\n",
    "probs = df[\"neural_ans3_prob\"].values\n",
    "dict_baselines[\"DQ2\"][\"probs\"] = 1 - probs\n",
    "ground_truth = df[\"bing_return\"].values\n",
    "ground_truth = [0 if x == True else 1 for x in ground_truth]\n",
    "ground_truth = np.array(ground_truth)\n",
    "dict_baselines[\"DQ2\"][\"ground_truth\"] = ground_truth\n",
    "\n",
    "probs = df[\"neural_ans4_prob\"].values\n",
    "dict_baselines[\"DQ3\"][\"probs\"] = 1 - probs\n",
    "ground_truth = df[\"bing_return\"].values\n",
    "ground_truth = [0 if x == True else 1 for x in ground_truth]\n",
    "ground_truth = np.array(ground_truth)\n",
    "dict_baselines[\"DQ3\"][\"ground_truth\"] = ground_truth\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(18, 4))\n",
    "\n",
    "# loop over the subplots and plot the ROC curve for each one\n",
    "for i, ax in enumerate(axes):\n",
    "    # calculate the fpr and tpr for all thresholds of the claIQification\n",
    "    ground_truth = dict_baselines[list_baselines[i]][\"ground_truth\"]\n",
    "    probs = dict_baselines[list_baselines[i]][\"probs\"]\n",
    "    ret_mean = plot_roc_bootstrap(X=probs, y=ground_truth, pos_label=pos_label,\n",
    "                   n_bootstrap=n_samples,\n",
    "                   random_state=42,\n",
    "                   show_boots=False,\n",
    "                   ax=ax)\n",
    "    auc, auc_var, ci = auc_ci_Delong(y_true=ground_truth,y_scores=probs)\n",
    "    error_delta =  ret_mean[\"auc_mean\"] - ci[0]\n",
    "    ax.set_title(f'ROC: {list_baselines[i]}, AUC: {ret_mean[\"auc_mean\"]:.3f} ± {error_delta:.2f}',fontsize=15)\n",
    "    ax.plot([0, 1], [0, 1],'r--')\n",
    "    ax.set_xlim([0, 1])\n",
    "    ax.set_ylim([0, 1])\n",
    "    if i > 0:\n",
    "        ax.set_xlabel('1 - G accuracy',fontsize=15)\n",
    "        ax.set_ylabel('',fontsize=15)\n",
    "        continue\n",
    "    ax.set_ylabel('H accuracy',fontsize=15)\n",
    "    ax.set_xlabel('1 - G accuracy',fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Combined ROC Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from roc_utils import *\n",
    "\n",
    "pos_label = 1\n",
    "n_samples = 100\n",
    "# aIQuming your dataframe is called df and has columns \"probs\" and \"ground truth\"\n",
    "list_baselines =  [\"IQ\",\"DQ1\",\"DQ2\",\"DQ3\",\"IQ+DQ\",\"DQ\",\"IQ+DQ1\",\"IQ+DQ2\",\"IQ+DQ3\"]#,\"IQ+DQ2\"]\n",
    "dict_baselines = {\"IQ\":  None,\"DQ1\": None,\"DQ2\":  None,\"DQ3\": None,\"IQ+DQ\" : None,\"DQ\" : None, \"IQ+DQ1\": None, \"IQ+DQ2\": None, \"IQ+DQ3\": None}\n",
    "\n",
    "ground_truth = df[\"bing_return\"].values\n",
    "ground_truth = [0 if x == True else 1 for x in ground_truth]\n",
    "ground_truth = np.array(ground_truth)\n",
    "\n",
    "\n",
    "probs = df[\"neural_ans1_prob\"].values\n",
    "dict_baselines[\"IQ\"] = 1 - probs\n",
    "\n",
    "probs = df[\"neural_ans2_prob\"].values\n",
    "dict_baselines[\"DQ1\"] = 1 - probs\n",
    "\n",
    "probs = df[\"neural_ans3_prob\"].values\n",
    "dict_baselines[\"DQ2\"] = 1 - probs\n",
    "\n",
    "\n",
    "probs = df[\"neural_ans4_prob\"].values\n",
    "dict_baselines[\"DQ3\"] = 1 - probs\n",
    "\n",
    "#probs = df[\"neural_ans4_prob\"].values\n",
    "dict_baselines[\"DQ\"] = np.mean([dict_baselines[\"DQ1\"],dict_baselines[\"DQ2\"],dict_baselines[\"DQ3\"]],axis=0)\n",
    "\n",
    "dict_baselines[\"IQ+DQ\"] = np.mean([dict_baselines[\"IQ\"],dict_baselines[\"DQ\"]],axis=0)\n",
    "dict_baselines[\"IQ+DQ1\"] = np.mean([dict_baselines[\"IQ\"],dict_baselines[\"DQ1\"]],axis=0)\n",
    "dict_baselines[\"IQ+DQ2\"] = np.mean([dict_baselines[\"IQ\"],dict_baselines[\"DQ2\"]],axis=0)\n",
    "dict_baselines[\"IQ+DQ3\"] = np.mean([dict_baselines[\"IQ\"],dict_baselines[\"DQ3\"]],axis=0)\n",
    "\n",
    "# create a figure with four subplots\n",
    "fig, axes = plt.subplots(1, 5, figsize=(22, 6))\n",
    "\n",
    "# loop over the subplots and plot the ROC curve for each one\n",
    "for i, ax in enumerate(axes):\n",
    "    # calculate the fpr and tpr for all thresholds of the claIQification\n",
    "    probs = dict_baselines[list_baselines[i+4]]\n",
    "    ret_mean = plot_roc_bootstrap(X=probs, y=ground_truth, pos_label=pos_label,\n",
    "                   n_bootstrap=n_samples,\n",
    "                   random_state=42,\n",
    "                   show_boots=False,\n",
    "                   title=\"\",\n",
    "                   ax=ax)\n",
    "    auc, auc_var, ci = auc_ci_Delong(y_true=ground_truth,y_scores=probs)\n",
    "    error_delta =  ret_mean[\"auc_mean\"] - ci[0]\n",
    "    ax.set_title(f'{list_baselines[i+4]}, AUC: {ret_mean[\"auc_mean\"]:.3f} ± {error_delta:.2f}',fontsize=15)\n",
    "    ax.plot([0, 1], [0, 1],'r--')\n",
    "    ax.set_xlim([-0.05, 1])\n",
    "    ax.set_ylim([0, 1.05])\n",
    "    if i > 0:\n",
    "        ax.set_xlabel('1 - G accuracy',fontsize=15)\n",
    "        ax.set_ylabel('',fontsize=15)\n",
    "        continue\n",
    "    ax.set_ylabel('H accuracy',fontsize=15)\n",
    "    ax.set_xlabel('1 - G accuracy',fontsize=15)\n",
    "    \n",
    "#plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FDR curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fdr_boot_extended(x_boot,y_boot,return_min,col_name):\n",
    "    thresholds = np.linspace(-0.05, 0.99, 50)\n",
    "    error_tolerance = 0.001\n",
    "    \n",
    "    fdr = []\n",
    "    returns = []\n",
    "    df_boot = pd.concat([x_boot,y_boot],axis=1)    \n",
    "    #glob_lis = []\n",
    "    min_returns = 10000\n",
    "    min_threshold = 10000\n",
    "    for threshold in thresholds:\n",
    "        df_boot_TP = df_boot[(df_boot[col_name] <= threshold) & (df_boot[\"bing_return\"] == False)]\n",
    "        TP = len(df_boot_TP)\n",
    "        df_boot_TN = df_boot[(df_boot[col_name] > threshold) & (df_boot[\"bing_return\"] == True)]\n",
    "        TN = len(df_boot_TN)\n",
    "        df_boot_FP = df_boot[(df_boot[col_name] <= threshold) & (df_boot[\"bing_return\"] == True)]\n",
    "        FP = len(df_boot_FP)\n",
    "        df_boot_FN = df_boot[(df_boot[col_name] > threshold) & (df_boot[\"bing_return\"] == False)]\n",
    "        FN = len(df_boot_FN)\n",
    "        FDR = FN/(TN + FN)\n",
    "        RETURNS = (TN + FN)/(TP + TN + FP + FN)\n",
    "        fdr.append(FDR)\n",
    "        returns.append(RETURNS)\n",
    "        if RETURNS < min_returns:\n",
    "            min_returns = RETURNS\n",
    "            min_threshold = threshold\n",
    "\n",
    "    assert min_threshold != 10000\n",
    "    ext_x = []\n",
    "    ext_y = []\n",
    "    extended_points = np.linspace(0.01,min_returns, 20)\n",
    "    for point in extended_points:\n",
    "        num_samples_ext = int((TP + TN + FP + FN)*point)\n",
    "        df_fdr_boot_ext = df_boot[(df_boot[col_name] > min_threshold)].sample(n=num_samples_ext,random_state=1)\n",
    "        assert num_samples_ext == len(df_fdr_boot_ext)\n",
    "        ext_FN = len(df_fdr_boot_ext[(df_fdr_boot_ext[col_name] > min_threshold) & (df_fdr_boot_ext[\"bing_return\"] == False)])\n",
    "        assert ext_FN <= len(df_fdr_boot_ext)\n",
    "        ext_y.append(ext_FN/num_samples_ext)\n",
    "        ext_x.append(num_samples_ext/(TP + TN + FP + FN))\n",
    "        \n",
    "    return fdr,returns,ext_x,ext_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(42, np.random.RandomState)\n",
    "if not isinstance(42, np.random.RandomState):\n",
    "        random_state = np.random.RandomState(42)\n",
    "random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.linspace(-0.05, 0.99, 50)\n",
    "\n",
    "def get_fdr(threshold,prompt_type,df_arg):\n",
    "    col = \"neural_ans\"+str(prompt_type)+\"_prob\"\n",
    "    TP_df = df_arg[(df_arg[col] <= threshold) & (df_arg[\"bing_return\"] == False)]\n",
    "    TP = len(TP_df)\n",
    "    TN_df = df_arg[(df_arg[col] > threshold) & (df_arg[\"bing_return\"] == True)]\n",
    "    TN = len(TN_df)\n",
    "    FP_df = df_arg[(df_arg[col] <= threshold) & (df_arg[\"bing_return\"] == True)]\n",
    "    FP = len(FP_df)\n",
    "    FN_df = df_arg[(df_arg[col] > threshold) & (df_arg[\"bing_return\"] == False)]\n",
    "    FN = len(FN_df)\n",
    "    FDR = FN/(TN + FN)\n",
    "    returns = (TN + FN)/(TP + TN + FP + FN)\n",
    "    return FDR,returns\n",
    "IQ_fdr = []\n",
    "IQ_return = []\n",
    "\n",
    "for i in thresholds:\n",
    "    fdr,returns = get_fdr(i,1,df)\n",
    "    IQ_fdr.append(fdr)\n",
    "    IQ_return.append(returns)\n",
    "\n",
    "IQ_fdr = np.array(IQ_fdr)\n",
    "IQ_return = np.array(IQ_return)\n",
    "\n",
    "DQ1_fdr = []\n",
    "DQ1_return = []\n",
    "\n",
    "for i in thresholds:\n",
    "    fdr,returns = get_fdr(i,2,df)\n",
    "    DQ1_fdr.append(fdr)\n",
    "    DQ1_return.append(returns)\n",
    "    \n",
    "DQ1_fdr = np.array(DQ1_fdr)\n",
    "DQ1_return = np.array(DQ1_return)\n",
    "\n",
    "DQ2_fdr = []\n",
    "DQ2_return = []\n",
    "for i in thresholds:\n",
    "    fdr,returns = get_fdr(i,3,df)\n",
    "    DQ2_fdr.append(fdr)\n",
    "    DQ2_return.append(returns)\n",
    "DQ2_fdr = np.array(DQ2_fdr)\n",
    "DQ2_return = np.array(DQ2_return)\n",
    "\n",
    "DQ3_fdr = []\n",
    "DQ3_return = []\n",
    "for i in thresholds:\n",
    "    fdr,returns = get_fdr(i,4,df)\n",
    "    DQ3_fdr.append(fdr)\n",
    "    DQ3_return.append(returns)\n",
    "DQ3_fdr = np.array(DQ3_fdr)\n",
    "DQ3_return = np.array(DQ3_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_interpolation(x, y):\n",
    "    def interpolate(new_x):\n",
    "        if new_x <= x[0]:\n",
    "            return y[0]\n",
    "        elif new_x >= x[-1]:\n",
    "            return y[-1]\n",
    "        else:\n",
    "            for i in range(len(x)-1):\n",
    "                if x[i] <= new_x <= x[i+1]:\n",
    "                    slope = (y[i+1] - y[i]) / (x[i+1] - x[i])\n",
    "                    return y[i] + slope * (new_x - x[i])\n",
    "    return interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 100\n",
    "resolution = 101\n",
    "def get_all_data_with_extension(prompt_type,return_min,return_max):\n",
    "    results = []\n",
    "    glob_n_lis = []\n",
    "    ext_results = []\n",
    "    for n_sample in range(n_samples):\n",
    "        col_name = \"neural_ans\"+str(prompt_type)+\"_prob\"\n",
    "        x_boot, y_boot = roc_utils._sampling.resample_data(df[col_name],df[\"bing_return\"],random_state = random_state,replace=True,stratify=None)\n",
    "        fdr,returns,ext_x,ext_y = get_fdr_boot_extended(x_boot,y_boot,return_min,col_name)\n",
    "        results.append((fdr,returns))\n",
    "        #glob_n_lis.extend(ext_data)\n",
    "        ext_results.append((ext_x,ext_y))\n",
    "\n",
    "    fdr_all = np.zeros((n_samples,resolution))\n",
    "    mean = np.linspace(return_min,return_max,resolution)\n",
    "    for i in range(n_samples):\n",
    "   \n",
    "        Q = list(set(zip(results[i][1],results[i][0])))\n",
    "        Q.sort(key=lambda x: x[0])\n",
    "        #print(Q)\n",
    "        x = [i[0] for i in Q]\n",
    "        y = [i[1] for i in Q]\n",
    "        f = linear_interpolation(x,y)\n",
    "        fdr_all[i,:] = np.array([f(j) for j in mean])\n",
    "\n",
    "    \n",
    "    ext_mean = np.linspace(0.01,return_min,20) #change the starting point for text-davinci-003\n",
    "    ext_all = np.zeros((n_samples,20))\n",
    "    for i in range(n_samples):\n",
    "        Q = list(set(zip(ext_results[i][0],ext_results[i][1])))\n",
    "        Q.sort(key=lambda x: x[0])\n",
    "        #print(Q)\n",
    "        x = [i[0] for i in Q]\n",
    "        y = [i[1] for i in Q]\n",
    "        f = linear_interpolation(x,y)\n",
    "        ext_all[i,:] = np.array([f(j) for j in ext_mean])\n",
    "\n",
    "    fdr_sort = np.sort(fdr_all, axis=0)\n",
    "    fdr_lower = fdr_sort[int(0.025 * n_samples), :]\n",
    "    fdr_upper = fdr_sort[int(0.975 * n_samples), :]\n",
    "    fdr_std = np.std(fdr_all, axis=0, ddof=1)\n",
    "    fdr_mean = np.mean(fdr_all, axis=0)\n",
    "    fdr_lower_ci = fdr_mean - 1.96 * fdr_std / np.sqrt(n_samples)\n",
    "    fdr_upper_ci = fdr_mean + 1.96 * fdr_std / np.sqrt(n_samples)\n",
    "\n",
    "    ext_sort = np.sort(ext_all, axis=0)\n",
    "    ext_lower = ext_sort[int(0.025 * n_samples), :]\n",
    "    ext_upper = ext_sort[int(0.975 * n_samples), :]\n",
    "    ext_std = np.std(ext_all, axis=0, ddof=1)\n",
    "    ext_mean_fdr = np.mean(ext_all, axis=0)\n",
    "    ext_lower_ci = ext_mean_fdr - 1.96 * ext_std / np.sqrt(n_samples)\n",
    "    ext_upper_ci = ext_mean_fdr + 1.96 * ext_std / np.sqrt(n_samples)\n",
    "\n",
    "    return mean,fdr_lower,fdr_upper,fdr_lower_ci,fdr_upper_ci,ext_mean,ext_mean_fdr,ext_lower,ext_upper,ext_lower_ci,ext_upper_ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdr_dict_data = [{\"IQ\":{\"y\":IQ_fdr,\"x\":IQ_return}},{\"DQ1\" : {\"y\":DQ1_fdr,\"x\":DQ1_return}},{\"DQ2\" : {\"y\":DQ2_fdr,\"x\":DQ2_return}},{\"DQ3\" : {\"y\":DQ3_fdr,\"x\":DQ3_return}}]\n",
    "prompt_types = [\"1\",\"2\",\"3\",\"4\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "colors = ['black','b', 'g', 'r']\n",
    "linestyles = ['solid','dashed', 'dashdot', 'dotted']\n",
    "# loop over the data and plot the ROC curve for each one\n",
    "for i in range(len(fdr_dict_data)):\n",
    "#for i in range(1):\n",
    "    x = fdr_dict_data[i][list(fdr_dict_data[i].keys())[0]][\"x\"]\n",
    "    y = fdr_dict_data[i][list(fdr_dict_data[i].keys())[0]][\"y\"]\n",
    "    if prompt_types[i] == \"1\":\n",
    "        return_min = np.min(IQ_return)\n",
    "        return_max = np.max(IQ_return)\n",
    "    if prompt_types[i] == \"2\":\n",
    "        return_min = np.min(DQ1_return)\n",
    "        return_max = np.max(DQ1_return)\n",
    "    if prompt_types[i] == \"3\":\n",
    "        return_min = np.min(DQ2_return)\n",
    "        return_max = np.max(DQ2_return)\n",
    "    if prompt_types[i] == \"4\":\n",
    "        return_min = np.min(DQ3_return)\n",
    "        return_max = np.max(DQ3_return)\n",
    "\n",
    "    mean,fdr_lower,fdr_upper,fdr_lower_ci,fdr_upper_ci,ext_mean,ext_mean_fdr,ext_lower,ext_upper,ext_lower_ci,ext_upper_ci = get_all_data_with_extension(prompt_types[i],return_min,return_max)\n",
    "    \n",
    "    x = np.concatenate((ext_mean[:-1],x))\n",
    "    y = np.concatenate((ext_mean_fdr[:-1],y))\n",
    "    set_xy = zip(x,y)\n",
    "    set_xy = sorted(set_xy)\n",
    "    x,y = zip(*set_xy)\n",
    "\n",
    "    x_mean = np.concatenate((ext_mean[:-1],mean))\n",
    "    y_lower_ci = np.concatenate((ext_lower_ci[:-1],fdr_lower_ci))\n",
    "    y_upper_ci = np.concatenate((ext_upper_ci[:-1],fdr_upper_ci))\n",
    "    y_upper = np.concatenate((ext_upper[:-1],fdr_upper))\n",
    "    y_lower = np.concatenate((ext_lower[:-1],fdr_lower))\n",
    "    set_xy = zip(x_mean,y_lower_ci)\n",
    "    set_xy = sorted(set_xy)\n",
    "    x_mean,y_lower_ci = zip(*set_xy)\n",
    "    set_xy = zip(x_mean,y_upper_ci)\n",
    "    set_xy = sorted(set_xy)\n",
    "    x_mean,y_upper_ci = zip(*set_xy)\n",
    "    set_xy = zip(x_mean,y_upper)\n",
    "    set_xy = sorted(set_xy)\n",
    "    x_mean,y_upper = zip(*set_xy)\n",
    "    set_xy = zip(x_mean,y_lower)\n",
    "    set_xy = sorted(set_xy)\n",
    "    x_mean,y_lower = zip(*set_xy)\n",
    "\n",
    "    ax.plot(x,y, label=list(fdr_dict_data[i].keys())[0],color=colors[i],linewidth=1.5,linestyle = linestyles[i])\n",
    "    ax.fill_between(x_mean,y_lower, y_upper,color=colors[i], alpha=.2,zorder=2)\n",
    "    ax.fill_between(x_mean,y_lower_ci, y_upper_ci,color=colors[i], alpha=.3,zorder=1)\n",
    "    ax.legend(loc='upper left',fontsize=25)\n",
    "    ax.set_ylabel('False discovery rate',fontsize=25)\n",
    "    ax.set_xlabel('Fraction of references preserved',fontsize=25)\n",
    "    ax.tick_params(axis='x', labelsize=20)\n",
    "    ax.tick_params(axis='y', labelsize=20)\n",
    "    ax.set_xlim([0, 1.05])\n",
    "    ax.set_ylim([0, 0.50])\n",
    "    print(\"done\")\n",
    "ax.set_title(\"GPT-4\",fontsize=25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
